<!-- static/index.html -->
<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8" />
  <title>Azure Speech AI Chat</title>
  <!-- Faviconのリンクを追加 -->
  <link rel="icon" href="/static/favicon.ico" type="image/x-icon" />
  
  <!-- Azure Cognitive Services Speech SDK JS (CDN) -->
  <script src="https://aka.ms/csspeech/jsbrowserpackageraw"></script>
  <style>
    body { font-family: Arial, sans-serif; margin: 50px; }
    #chat { border: 1px solid #ccc; padding: 10px; height: 300px; overflow-y: scroll; }
    .message { margin: 10px 0; }
    .user { color: blue; }
    .ai { color: green; }
    button { padding: 10px 20px; margin: 5px; }
    #status { margin-top: 10px; }
    #result { margin-top: 10px; font-weight: bold; }
  </style>
</head>
<body>
  <h1>Azure Speech AIチャットアプリ</h1>
  <div id="chat"></div>
  <button id="startBtn">音声認識開始</button>
  <button id="stopBtn" disabled>音声認識停止</button>
  <button id="resetBtn">リセット</button>
  <p id="status"></p>
  <p id="result"></p>

  <script>
    let audioConfig, speechRecognizer;
    let accumulatedText = ''; // 認識結果を蓄積する変数
    let conversationHistory = []; // 会話履歴を保持する配列
    let accumulatedPartialText = ''; // AIの部分的な応答を蓄積する変数

    // 音声再生のキューと再生状態の管理
    let audioQueue = [];
    let isPlaying = false;

    // ローカルストレージから会話履歴を読み込む
    window.onload = function() {
      const savedHistory = localStorage.getItem('conversationHistory');
      if (savedHistory) {
        conversationHistory = JSON.parse(savedHistory);
        conversationHistory.forEach(msg => addMessage(msg.content, msg.role === 'user' ? 'user' : 'ai'));
      }
    };

    // チャット履歴をローカルストレージに保存
    function saveConversation() {
      localStorage.setItem('conversationHistory', JSON.stringify(conversationHistory));
    }

    document.getElementById("startBtn").onclick = async function() {
      document.getElementById("status").innerText = "トークン取得中...";
      accumulatedText = ''; // 認識開始前に蓄積テキストをリセット
      accumulatedPartialText = ''; // AIの部分的な応答もリセット

      try {
        // サーバー(Flask)からトークンとリージョンをGET
        let resp = await fetch("/token");
        let data = await resp.json();
        if (data.error) {
          throw new Error(data.error);
        }
        let token = data.token;
        let region = data.region;

        // JavaScript SDKのSpeechConfigをToken連携モードで作成
        let speechConfig = SpeechSDK.SpeechConfig.fromAuthorizationToken(token, region);
        speechConfig.speechRecognitionLanguage = "ja-JP"; // 必要に応じて

        // タイムアウト設定の変更
        // EndSilenceTimeoutMs を30秒に設定（デフォルトは5000ms）
        speechConfig.setProperty(SpeechSDK.PropertyId.SpeechServiceConnection_EndSilenceTimeoutMs, "30000");

        // 初期無音タイムアウトも延長（必要に応じて）
        speechConfig.setProperty(SpeechSDK.PropertyId.SpeechServiceConnection_InitialSilenceTimeoutMs, "10000");

        // ノイズ抑制の有効化（オプション）
        speechConfig.setProperty(SpeechSDK.PropertyId.SpeechServiceConnection_EnableNoiseSuppression, "true");

        // マイクアクセス(ユーザーが「許可」する必要あり)
        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
        audioConfig = SpeechSDK.AudioConfig.fromDefaultMicrophoneInput();

        // SpeechRecognizerを作成
        speechRecognizer = new SpeechSDK.SpeechRecognizer(speechConfig, audioConfig);
        document.getElementById("status").innerText = "音声認識を開始します...";

        // 認識開始イベント
        speechRecognizer.sessionStarted = (s, e) => {
          console.log("sessionStarted");
          document.getElementById("status").innerText = "録音中...(話してください)";
        };

        // 認識途中のイベント (部分的な結果)
        speechRecognizer.recognizing = (s, e) => {
          console.log("Recognizing:", e.result.text);
          document.getElementById("result").innerText = "途中結果: " + e.result.text;
          // 部分結果は蓄積しない
        };

        // 認識確定イベント (最終結果)
        speechRecognizer.recognized = (s, e) => {
          console.log("Recognized:", e.result);
          if (e.result.reason === SpeechSDK.ResultReason.RecognizedSpeech) {
            document.getElementById("result").innerText = "最終結果: " + e.result.text;
            accumulatedText += e.result.text + ' '; // テキストを蓄積
          } else {
            document.getElementById("result").innerText = "認識できませんでした";
          }
        };

        // セッション終了(マイク停止など)
        speechRecognizer.sessionStopped = (s, e) => {
          console.log("sessionStopped");
          document.getElementById("status").innerText = "認識セッションが終了しました。";
          document.getElementById("stopBtn").disabled = true;
          document.getElementById("startBtn").disabled = false;
          document.getElementById("resetBtn").disabled = false;

          if (accumulatedText.trim() !== '') {
            addMessage(accumulatedText.trim(), 'user'); // ユーザーのメッセージをチャットに追加
            sendChatAndStreamResponse(accumulatedText.trim()); // AIにメッセージを送信してストリーミング応答を処理
          }
          accumulatedText = ''; // 蓄積テキストをリセット
        };

        // エラーイベント
        speechRecognizer.canceled = (s, e) => {
          console.warn("canceled", e);
          document.getElementById("status").innerText = "キャンセルまたはエラー";
          document.getElementById("stopBtn").disabled = true;
          document.getElementById("startBtn").disabled = false;
          document.getElementById("resetBtn").disabled = false;
          accumulatedText = ''; // 蓄積テキストをリセット
        };

        // 実際に認識開始
        speechRecognizer.startContinuousRecognitionAsync();
        document.getElementById("startBtn").disabled = true;
        document.getElementById("stopBtn").disabled = false;
        document.getElementById("resetBtn").disabled = true; // リセットボタンを無効化
      } catch (err) {
        console.error(err);
        document.getElementById("status").innerText = "エラー: " + err.message;
      }
    };

    document.getElementById("stopBtn").onclick = function() {
      if (speechRecognizer) {
        speechRecognizer.stopContinuousRecognitionAsync(
          () => {
            console.log("stop success");
            document.getElementById("status").innerText = "認識停止";
            document.getElementById("stopBtn").disabled = true;
            document.getElementById("startBtn").disabled = false;
            document.getElementById("resetBtn").disabled = false;
          },
          (err) => {
            console.error("stop error", err);
            document.getElementById("status").innerText = "停止中にエラーが発生";
          }
        );
      }
    };

    // リセットボタンの実装
    document.getElementById("resetBtn").onclick = function() {
      conversationHistory = []; // 会話履歴をリセット
      document.getElementById("chat").innerHTML = ''; // チャット表示をクリア
      document.getElementById("result").innerText = ''; // 認識結果表示をクリア
      document.getElementById("status").innerText = '会話がリセットされました。';
      document.getElementById("resetBtn").disabled = true; // リセットボタンを無効化
      localStorage.removeItem('conversationHistory'); // ローカルストレージをクリア
    };

    function addMessage(message, sender) {
      const chatDiv = document.getElementById('chat');
      const messageDiv = document.createElement('div');
      messageDiv.classList.add('message', sender);
      messageDiv.innerHTML = `<strong>${sender === 'user' ? 'You' : 'AI'}:</strong> ${message}`;
      chatDiv.appendChild(messageDiv);
      chatDiv.scrollTop = chatDiv.scrollHeight;

      // 会話履歴に追加
      if (sender === 'user') {
        conversationHistory.push({ role: 'user', content: message });
      } else if (sender === 'ai') {
        conversationHistory.push({ role: 'assistant', content: message });
      }

      // チャット履歴をローカルストレージに保存
      saveConversation();
    }

    async function sendChatAndStreamResponse(userMessage) {
      try {
        const response = await fetch('/api/chat', {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json'
          },
          body: JSON.stringify({ conversation: conversationHistory }) // 会話履歴を送信
        });

        if (!response.ok) {
          throw new Error('チャットリクエストに失敗しました。');
        }

        const reader = response.body.getReader();
        const decoder = new TextDecoder('utf-8');
        let buffer = '';

        while (true) {
          const { done, value } = await reader.read();
          if (done) break;
          buffer += decoder.decode(value, { stream: true });
          const lines = buffer.split('\n\n');
          buffer = lines.pop(); // 最後の行が未完の可能性があるのでバッファに戻す

          for (const line of lines) {
            if (line.startsWith("data: ")) {
              const jsonData = line.replace("data: ", "");
              try {
                const data = JSON.parse(jsonData);
                if (data.error) {
                  addMessage(data.error, 'ai');
                  continue;
                }
                const content = data.content;
                if (content === "【END】") {
                  // 送信が終了したことを示す
                  if (accumulatedPartialText.trim() !== '') {
                    enqueueTTSRequest(accumulatedPartialText.trim());
                    accumulatedPartialText = '';
                  }
                  continue;
                }

                // Append to accumulatedPartialText
                accumulatedPartialText += content;

                // Check for sentence boundary (。、！、？)
                let sentenceEndIndex;
                while ((sentenceEndIndex = accumulatedPartialText.search(/[。！？]/)) !== -1) {
                  const sentence = accumulatedPartialText.slice(0, sentenceEndIndex + 1);
                  accumulatedPartialText = accumulatedPartialText.slice(sentenceEndIndex + 1);
                  addMessage(sentence, 'ai'); // AIのメッセージをチャットに追加
                  enqueueTTSRequest(sentence); // 完全な文をTTSに送信
                }

              } catch (e) {
                console.error("Error parsing JSON:", e);
                continue;
              }
            }
          }
        }

      } catch (err) {
        console.error(err);
        addMessage('サーバーとの通信中にエラーが発生しました。', 'ai');
      }
    }

    function enqueueTTSRequest(text) {
      audioQueue.push(text);
      if (!isPlaying) {
        playNextAudio();
      }
    }

    function playNextAudio() {
      if (audioQueue.length === 0) {
        isPlaying = false;
        return;
      }
      isPlaying = true;
      const text = audioQueue.shift();
      sendTTSRequest(text).then(() => {
        playNextAudio();
      }).catch(err => {
        console.error(err);
        addMessage('音声再生中にエラーが発生しました。', 'ai');
        playNextAudio();
      });
    }

    async function sendTTSRequest(text) {
      try {
        const response = await fetch('/api/tts', {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json'
          },
          body: JSON.stringify({ text: text })
        });

        if (!response.ok) {
          const errorData = await response.json();
          throw new Error(errorData.error || 'TTSリクエストに失敗しました。');
        }

        const audioBlob = await response.blob();
        const audioUrl = URL.createObjectURL(audioBlob);
        const audio = new Audio(audioUrl);

        return new Promise((resolve, reject) => {
          audio.onended = () => {
            resolve();
          };
          audio.onerror = () => {
            reject(new Error('音声再生に失敗しました。'));
          };
          audio.play();
        });
      } catch (err) {
        console.error(err);
        addMessage('音声再生中にエラーが発生しました。', 'ai');
        throw err;
      }
    }
  </script>
</body>
</html>
